{
  "data": {
    "lesson": {
      "id": 619972,
      "key": "5c4faf40-5fa7-4004-85cf-ff7e86d596a0",
      "title": "Hyperparameters",
      "semantic_type": "Lesson",
      "is_public": true,
      "version": "1.0.0",
      "locale": "en-us",
      "summary": "Learn about a number of different hyperparameters that are used in defining and training deep learning models. We'll discuss starting values and intuitions for tuning each hyperparameter.",
      "lesson_type": "Classroom",
      "display_workspace_project_only": null,
      "resources": {
        "files": [
          {
            "name": "Videos Zip File",
            "uri": "https://zips.udacity-data.com/5c4faf40-5fa7-4004-85cf-ff7e86d596a0/619972/1544453141983/Hyperparameters+Videos.zip"
          },
          {
            "name": "Transcripts Zip File",
            "uri": "https://zips.udacity-data.com/5c4faf40-5fa7-4004-85cf-ff7e86d596a0/619972/1544453139221/Hyperparameters+Subtitles.zip"
          }
        ],
        "google_plus_link": null,
        "career_resource_center_link": null,
        "coaching_appointments_link": null,
        "office_hours_link": null,
        "aws_provisioning_link": null
      },
      "project": null,
      "lab": null,
      "concepts": [
        {
          "id": 354295,
          "key": "7d348cf7-e3e6-4223-a56e-a1c2d32a718e",
          "title": "Introducing Jay",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "7d348cf7-e3e6-4223-a56e-a1c2d32a718e",
            "completed_at": "2020-04-01T05:29:19.965Z",
            "last_viewed_at": "2020-04-01T05:29:18.966Z",
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 354297,
              "key": "5e3b3d70-81e1-409f-9856-133cf518ad70",
              "title": null,
              "semantic_type": "ImageAtom",
              "is_public": true,
              "url": "https://video.udacity-data.com/topher/2017/August/5981217f_f3iwvmld-400x400/f3iwvmld-400x400.jpg",
              "non_google_url": "https://s3.cn-north-1.amazonaws.com.cn/u-img/5e3b3d70-81e1-409f-9856-133cf518ad70",
              "caption": "",
              "alt": null,
              "width": 400,
              "height": 400,
              "instructor_notes": null
            },
            {
              "id": 354296,
              "key": "99542acd-d02a-433a-9390-cf1abb72844f",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "For this section, we're introducing a new Udacity instructor, Jay Alammar. Jay has done some great work in interactive explorations of neural networks, check out [his blog](http://jalammar.github.io/).\n\nJay will be reviewing some of the material you saw in the Deep Neural Networks section on hyperparameters, and he will also introduce the hyperparameters used in Recurrent Neural Networks.",
              "instructor_notes": ""
            }
          ]
        },
        {
          "id": 302698,
          "key": "cbe2be25-39f4-4b33-bd9f-1875bd047bc1",
          "title": "Introduction",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "cbe2be25-39f4-4b33-bd9f-1875bd047bc1",
            "completed_at": null,
            "last_viewed_at": null,
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 309449,
              "key": "b487b3e2-0458-447b-8776-bd2773d4d920",
              "title": "Introduction",
              "semantic_type": "VideoAtom",
              "is_public": true,
              "instructor_notes": "",
              "video": {
                "youtube_id": "erwnzFD7AeE",
                "china_cdn_id": "erwnzFD7AeE.mp4"
              }
            }
          ]
        },
        {
          "id": 302699,
          "key": "63add149-8f5c-4362-87ef-75c080592a4c",
          "title": "Learning Rate",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "63add149-8f5c-4362-87ef-75c080592a4c",
            "completed_at": null,
            "last_viewed_at": null,
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 309450,
              "key": "3ae7bcec-08fe-401b-bfa4-a5222e8bae5b",
              "title": "Learning Rate",
              "semantic_type": "VideoAtom",
              "is_public": true,
              "instructor_notes": "",
              "video": {
                "youtube_id": "HLMjeDez7ps",
                "china_cdn_id": "HLMjeDez7ps.mp4"
              }
            },
            {
              "id": 302704,
              "key": "2d4630ba-4594-4174-8c20-8aa5d08c8797",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "\n[Exponential Decay](https://www.tensorflow.org/api_docs/python/tf/train/exponential_decay) in TensorFlow.\n\n## Adaptive Learning Optimizers\n* [AdamOptimizer](https://www.tensorflow.org/api_docs/python/tf/train/AdamOptimizer)\n* [AdagradOptimizer](https://www.tensorflow.org/api_docs/python/tf/train/AdagradOptimizer)\n",
              "instructor_notes": ""
            }
          ]
        },
        {
          "id": 302700,
          "key": "ccc6ddc2-e2ae-47d2-b382-f48f242f1293",
          "title": "Learning Rate",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "ccc6ddc2-e2ae-47d2-b382-f48f242f1293",
            "completed_at": null,
            "last_viewed_at": null,
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 305736,
              "key": "dd79c64b-cf82-4087-b61c-b1fc541a27ee",
              "title": "Learning Rate Tuning #1",
              "semantic_type": "RadioQuizAtom",
              "is_public": true,
              "instructor_notes": null,
              "user_state": {
                "node_key": "dd79c64b-cf82-4087-b61c-b1fc541a27ee",
                "completed_at": null,
                "last_viewed_at": null,
                "unstructured": null
              },
              "question": {
                "prompt": "Say you're training a model. If the output from the training process looks as shown below, what action would you take on the learning rate to improve the training?\n\n    Epoch 1, Batch 1, Training Error: 8.4181\n    Epoch 1, Batch 2, Training Error: 8.4177\n    Epoch 1, Batch 3, Training Error: 8.4177\n    Epoch 1, Batch 4, Training Error: 8.4173\n    Epoch 1, Batch 5, Training Error: 8.4169",
                "answers": [
                  {
                    "id": "a1493874216567",
                    "text": "Decrease the learning rate",
                    "is_correct": false
                  },
                  {
                    "id": "a1493874597237",
                    "text": "Try again using the same learning rate",
                    "is_correct": false
                  },
                  {
                    "id": "a1493874611157",
                    "text": "Increase the learning rate",
                    "is_correct": true
                  }
                ]
              }
            },
            {
              "id": 305738,
              "key": "9c870ca8-2f91-4b62-8cb4-6ae874daa46c",
              "title": "Learning Rate Tuning #2",
              "semantic_type": "CheckboxQuizAtom",
              "is_public": true,
              "instructor_notes": null,
              "user_state": {
                "node_key": "9c870ca8-2f91-4b62-8cb4-6ae874daa46c",
                "completed_at": null,
                "last_viewed_at": null,
                "unstructured": null
              },
              "question": {
                "prompt": "Say you're training a model. If the output from the training process looks as shown below, what action would you take on the learning rate to improve the training?\n\n    Epoch 1, Batch 1, Training Error: 8.71\n    Epoch 1, Batch 2, Training Error: 3.25\n    Epoch 1, Batch 3, Training Error: 4.93\n    Epoch 1, Batch 4, Training Error: 3.30\n    Epoch 1, Batch 5, Training Error: 4.82",
                "answers": [
                  {
                    "id": "a1493876060387",
                    "text": "Decrease the learning rate",
                    "is_correct": true
                  },
                  {
                    "id": "a1493876268987",
                    "text": "Use an adaptive learning rate",
                    "is_correct": true
                  },
                  {
                    "id": "a1493876270139",
                    "text": "Increase the learning rate",
                    "is_correct": false
                  }
                ]
              }
            }
          ]
        },
        {
          "id": 302702,
          "key": "20cbcf7a-ea48-4464-9285-3c4b3af810e3",
          "title": "Minibatch Size",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "20cbcf7a-ea48-4464-9285-3c4b3af810e3",
            "completed_at": null,
            "last_viewed_at": null,
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 309451,
              "key": "68424af1-5dad-416a-a46a-49b9f8d93e00",
              "title": "Minibatch Size",
              "semantic_type": "VideoAtom",
              "is_public": true,
              "instructor_notes": "",
              "video": {
                "youtube_id": "GrrO1NFxaW8",
                "china_cdn_id": "GrrO1NFxaW8.mp4"
              }
            },
            {
              "id": 302705,
              "key": "9e0dca37-921d-4ed6-b61a-b8085bc05768",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "[Systematic evaluation of CNN advances on the ImageNet](https://arxiv.org/abs/1606.02228) by Dmytro Mishkin, Nikolay Sergievskiy, Jiri Matas",
              "instructor_notes": ""
            }
          ]
        },
        {
          "id": 302703,
          "key": "630da015-5d42-4321-b3f8-c827aa991d3e",
          "title": "Number of Training Iterations / Epochs",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "630da015-5d42-4321-b3f8-c827aa991d3e",
            "completed_at": null,
            "last_viewed_at": null,
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 309452,
              "key": "80ac99e7-5d01-4621-b862-52d4c7aa1144",
              "title": "Number Of Iterations",
              "semantic_type": "VideoAtom",
              "is_public": true,
              "instructor_notes": "",
              "video": {
                "youtube_id": "TTdHpSb4DV8",
                "china_cdn_id": "TTdHpSb4DV8.mp4"
              }
            },
            {
              "id": 302706,
              "key": "911f63ed-a380-4d82-8c81-5b7112556bb8",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "The number of training iterations is a hyperparameter we can optimize automatically using a technique called early stopping (also \"early termination\").\n\n## ValidationMonitor (Deprecated)\nIn tensorflow, we can use a [ValidationMonitor with tf.contrib.learn](https://www.tensorflow.org/get_started/monitors#early_stopping_with_validationmonitor ) to not only monitor the progress of training, but to also stop the training when certain conditions are met.\n\nThe following example from the ValidationMonitor documentation shows how to set it up. Note that the last three parameters indicate which metric we're optimizing. \n\n    validation_monitor = tf.contrib.learn.monitors.ValidationMonitor(\n      test_set.data,\n      test_set.target,\n      every_n_steps=50,\n      metrics=validation_metrics,\n      early_stopping_metric=\"loss\",\n      early_stopping_metric_minimize=True,\n      early_stopping_rounds=200)\n\nThe last parameter indicates to ValidationMonitor that it should stop the training process if the loss did not decrease in 200 steps (rounds) of training.\n\nThe validation_monitor is then passed to tf.contrib.learn's \"fit\" method which runs the training process:\n\n    classifier = tf.contrib.learn.DNNClassifier(\n      feature_columns=feature_columns,\n      hidden_units=[10, 20, 10],\n      n_classes=3,\n      model_dir=\"/tmp/iris_model\",\n      config=tf.contrib.learn.RunConfig(save_checkpoints_secs=1))\n\n    classifier.fit(x=training_set.data,\n               y=training_set.target,\n               steps=2000,\n               monitors=[validation_monitor])\n\n## SessionRunHook\n\nMore recent versions of TensorFlow deprecated monitors in favor of [SessionRunHooks](https://www.tensorflow.org/api_docs/python/tf/train/SessionRunHook). SessionRunHooks are an evolving part of tf.train, and going forward appear to be the proper place where you'd implement early stopping. \n\nAt the time of writing, two pre-defined stopping monitors exist as a part of tf.train's [training hooks](https://www.tensorflow.org/api_guides/python/train#Training_Hooks):\n\n  * [StopAtStepHook](https://www.tensorflow.org/api_docs/python/tf/train/StopAtStepHook): A monitor to request the training stop after a certain number of steps\n  * [NanTensorHook](https://www.tensorflow.org/api_docs/python/tf/train/NanTensorHook): a monitor that monitor's loss and stops training if it encounters a NaN loss",
              "instructor_notes": ""
            }
          ]
        },
        {
          "id": 302707,
          "key": "858bf729-ec9d-4f59-8fc1-1795a8a00082",
          "title": "Number of Hidden Units / Layers",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "858bf729-ec9d-4f59-8fc1-1795a8a00082",
            "completed_at": null,
            "last_viewed_at": null,
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 322175,
              "key": "a0acbea0-7e88-4802-8e92-ab43fa9bc334",
              "title": "Number Of Hidden Units Layers",
              "semantic_type": "VideoAtom",
              "is_public": true,
              "instructor_notes": "",
              "video": {
                "youtube_id": "IkGAIQH5wH8",
                "china_cdn_id": "IkGAIQH5wH8.mp4"
              }
            },
            {
              "id": 302708,
              "key": "837e58e0-bf08-4a3c-a8f5-4c26de10ac06",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "\"in practice it is often the case that 3-layer neural networks will outperform 2-layer nets, but going even deeper (4,5,6-layer) rarely helps much more. This is in stark contrast to Convolutional Networks, where depth has been found to be an extremely important component for a good recognition system (e.g. on order of 10 learnable layers).\" ~ Andrej Karpathy in https://cs231n.github.io/neural-networks-1/ \n\n## More on Capacity\nA more detailed discussion on a model's capacity appears in the [Deep Learning book, chapter 5.2](http://www.deeplearningbook.org/contents/ml.html) (pages 110-120).",
              "instructor_notes": ""
            }
          ]
        },
        {
          "id": 302709,
          "key": "a8510236-a0fe-41f3-9d19-254394349820",
          "title": "RNN Hyperparameters",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "a8510236-a0fe-41f3-9d19-254394349820",
            "completed_at": null,
            "last_viewed_at": null,
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 309454,
              "key": "88f50587-b2f2-4286-ba49-a900aa8f775b",
              "title": "RNN Hyperparameters",
              "semantic_type": "VideoAtom",
              "is_public": true,
              "instructor_notes": "",
              "video": {
                "youtube_id": "yQvnv7l_aUo",
                "china_cdn_id": "yQvnv7l_aUo.mp4"
              }
            },
            {
              "id": 302710,
              "key": "12337f0e-7e79-427c-afab-8e3bd31bb000",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "## LSTM Vs GRU\n\n\"These results clearly indicate the advantages of the gating units over the more traditional recurrent\nunits. Convergence is often faster, and the final solutions tend to be better. However, our results are\nnot conclusive in comparing the LSTM and the GRU, which suggests that the choice of the type of\ngated recurrent unit may depend heavily on the dataset and corresponding task.\" \n\n [Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling](https://arxiv.org/abs/1412.3555) by Junyoung Chung, Caglar Gulcehre, KyungHyun Cho, Yoshua Bengio\n\n\n\"The GRU outperformed the LSTM on all tasks with the exception of language modelling\" \n\n[An Empirical Exploration of Recurrent Network Architectures](http://proceedings.mlr.press/v37/jozefowicz15.pdf) by Rafal Jozefowicz,  Wojciech Zaremba, Ilya Sutskever\n\n\"Our consistent finding is that depth of at least two is\nbeneficial. However, between two and three layers our results are mixed. Additionally, the results\nare mixed between the LSTM and the GRU, but both significantly outperform the RNN.\"\n\n[Visualizing and Understanding Recurrent Networks](https://arxiv.org/abs/1506.02078) by Andrej Karpathy, Justin Johnson, Li Fei-Fei\n\n\"Which of these variants is best? Do the differences matter? [Greff, et al. (2015)](https://arxiv.org/pdf/1503.04069.pdf) do a nice comparison of popular variants, finding that theyâ€™re all about the same. [Jozefowicz, et al. (2015)](http://proceedings.mlr.press/v37/jozefowicz15.pdf) tested more than ten thousand RNN architectures, finding some that worked better than LSTMs on certain tasks.\"\n\n[Understanding LSTM Networks](https://colah.github.io/posts/2015-08-Understanding-LSTMs/) by Chris Olah\n\n\"In our [Neural Machine Translation] experiments, LSTM cells consistently outperformed GRU cells. Since the computational bottleneck in our architecture is the softmax operation we did not observe large difference in training speed between LSTM and GRU cells. Somewhat to our surprise, we found that the vanilla decoder is unable to learn nearly as well as the gated variant.\" \n\n[Massive Exploration of Neural Machine Translation Architectures](https://arxiv.org/abs/1703.03906v2) by Denny Britz, Anna Goldie, Minh-Thang Luong, Quoc Le",
              "instructor_notes": ""
            },
            {
              "id": 302711,
              "key": "6068d28f-d038-457c-acb3-5dcc04977853",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "## Example RNN Architectures\n\n|              Application              | Cell |  Layers |      Size     |          Vocabulary         | Embedding Size | Learning Rate |                                                                                       |\n|:-------------------------------------:|:---------:|:-------:|:-------------:|:---------------------------:|:--------------:|:-------------:|:-------------------------------------------------------------------------------------:|\n| Speech Recognition (large vocabulary) | LSTM      | 5, 7    | 600, 1000     | 82K, 500K                   | --             | --            | [paper](https://arxiv.org/abs/1610.09975)                                             |\n| Speech Recognition                    | LSTM      | 1, 3, 5 | 250           | --                          | --             | 0.001         | [paper](https://arxiv.org/abs/1303.5778)                                              |\n| Machine Translation (seq2seq)         | LSTM      | 4       | 1000          | Source: 160K, Target: 80K   | 1,000          | --            | [paper](https://arxiv.org/abs/1409.3215)                                              |\n| Image Captioning                      | LSTM      | --      | 512           | --                          | 512            | (fixed)       | [paper](https://arxiv.org/abs/1411.4555)                                              |\n| Image Generation                      | LSTM      | --      | 256, 400, 800 | --                          | --             | --            | [paper](https://arxiv.org/abs/1502.04623)                                             |\n| Question Answering                    | LSTM      | 2       | 500           | --                          | 300            | --            | [pdf](http://www.aclweb.org/anthology/P15-2116)                                       |\n| Text Summarization                    | GRU       |         | 200           | Source:  119K, Target:  68K | 100            | 0.001         | [pdf](https://pdfs.semanticscholar.org/3fbc/45152f20403266b02c4c2adab26fb367522d.pdf) |",
              "instructor_notes": ""
            }
          ]
        },
        {
          "id": 302712,
          "key": "c9c9302d-171d-4af9-9e5c-3007bba78f6f",
          "title": "RNN Hyperparameters",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "c9c9302d-171d-4af9-9e5c-3007bba78f6f",
            "completed_at": null,
            "last_viewed_at": null,
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 308344,
              "key": "d0dea3a9-97de-411b-bcf0-bf71f005107e",
              "title": "LSTM Vs. GRU",
              "semantic_type": "RadioQuizAtom",
              "is_public": true,
              "instructor_notes": null,
              "user_state": {
                "node_key": "d0dea3a9-97de-411b-bcf0-bf71f005107e",
                "completed_at": null,
                "last_viewed_at": null,
                "unstructured": null
              },
              "question": {
                "prompt": "How do Long Short Term Memory (LSTM) cells and Gated Recurrent Unit (GRU) cells compare?",
                "answers": [
                  {
                    "id": "a1494222466139",
                    "text": "LSTMs are superior to GRUs in every way",
                    "is_correct": false
                  },
                  {
                    "id": "a1494222582115",
                    "text": "GRUs are superior to LSTMs in every way",
                    "is_correct": false
                  },
                  {
                    "id": "a1494222592590",
                    "text": "It depends.. It's probably worth it to compare the two on my task and dataset.",
                    "is_correct": true
                  }
                ]
              }
            },
            {
              "id": 308342,
              "key": "312e944a-ce62-4574-8103-fc687022a83a",
              "title": "",
              "semantic_type": "RadioQuizAtom",
              "is_public": true,
              "instructor_notes": null,
              "user_state": {
                "node_key": "312e944a-ce62-4574-8103-fc687022a83a",
                "completed_at": null,
                "last_viewed_at": null,
                "unstructured": null
              },
              "question": {
                "prompt": "Which embedding size looks more reasonable for the majority of cases?",
                "answers": [
                  {
                    "id": "a1494221992596",
                    "text": "500",
                    "is_correct": true
                  },
                  {
                    "id": "a1494222085873",
                    "text": "50,000",
                    "is_correct": false
                  }
                ]
              }
            }
          ]
        },
        {
          "id": 302713,
          "key": "6d3834cc-b5be-442b-9581-1c5fcf1615a8",
          "title": "Sources & References",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "6d3834cc-b5be-442b-9581-1c5fcf1615a8",
            "completed_at": null,
            "last_viewed_at": null,
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 309227,
              "key": "50e8fdfd-0a22-484e-8dbf-899becbac619",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "If you want to learn more about hyperparameters, these are some great resources on the topic:\n\n* [Practical recommendations for gradient-based training of deep architectures](https://arxiv.org/abs/1206.5533) by Yoshua Bengio\n\n* [Deep Learning book - chapter 11.4: Selecting Hyperparameters](http://www.deeplearningbook.org/contents/guidelines.html) by Ian Goodfellow, Yoshua Bengio, Aaron Courville\n\n* [Neural Networks and Deep Learning book - Chapter 3: How to choose a neural network's hyper-parameters?](http://neuralnetworksanddeeplearning.com/chap3.html#how_to_choose_a_neural_network's_hyper-parameters) by Michael Nielsen\n\n* [Efficient BackProp (pdf)](http://yann.lecun.com/exdb/publis/pdf/lecun-98b.pdf) by Yann LeCun\n\n\nMore specialized sources:\n* [How to Generate a Good Word Embedding?](https://arxiv.org/abs/1507.05523) by Siwei Lai, Kang Liu, Liheng Xu, Jun Zhao\n* [Systematic evaluation of CNN advances on the ImageNet](https://arxiv.org/abs/1606.02228) by Dmytro Mishkin, Nikolay Sergievskiy, Jiri Matas\n* [Visualizing and Understanding Recurrent Networks](https://arxiv.org/abs/1506.02078)  by Andrej Karpathy, Justin Johnson, Li Fei-Fei",
              "instructor_notes": ""
            }
          ]
        }
      ]
    }
  },
  "_deprecated": [
    {
      "name": "non_google_url",
      "reason": "(2016/8/18) Not sure, ask i18n team for reason"
    }
  ]
}