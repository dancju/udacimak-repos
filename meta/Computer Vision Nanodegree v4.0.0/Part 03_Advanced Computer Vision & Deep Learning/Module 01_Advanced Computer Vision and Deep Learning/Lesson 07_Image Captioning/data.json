{
  "data": {
    "lesson": {
      "id": 621488,
      "key": "63ab2258-c681-410d-8aae-5cba7030b2af",
      "title": "Image Captioning",
      "semantic_type": "Lesson",
      "is_public": true,
      "version": "1.0.0",
      "locale": "en-us",
      "summary": "Learn how to combine CNNs and RNNs to build a complex, automatic image captioning model.",
      "lesson_type": "Classroom",
      "display_workspace_project_only": null,
      "resources": {
        "files": [
          {
            "name": "Videos Zip File",
            "uri": "https://zips.udacity-data.com/63ab2258-c681-410d-8aae-5cba7030b2af/621488/1544453404410/Image+Captioning+Videos.zip"
          },
          {
            "name": "Transcripts Zip File",
            "uri": "https://zips.udacity-data.com/63ab2258-c681-410d-8aae-5cba7030b2af/621488/1544453400455/Image+Captioning+Subtitles.zip"
          }
        ],
        "google_plus_link": null,
        "career_resource_center_link": null,
        "coaching_appointments_link": null,
        "office_hours_link": null,
        "aws_provisioning_link": null
      },
      "project": null,
      "lab": null,
      "concepts": [
        {
          "id": 621492,
          "key": "2080da18-31a7-4280-a89d-b492da176a40",
          "title": "Introduction to Image Captioning",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "2080da18-31a7-4280-a89d-b492da176a40",
            "completed_at": "2020-04-01T05:29:28.827Z",
            "last_viewed_at": "2020-04-01T05:29:27.839Z",
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 626320,
              "key": "51aaa7ec-6ddf-488e-ba6b-e0afdef2ba04",
              "title": "01 L Introduction V3",
              "semantic_type": "VideoAtom",
              "is_public": true,
              "instructor_notes": "",
              "video": {
                "youtube_id": "dobNslC2y-o",
                "china_cdn_id": "dobNslC2y-o.mp4"
              }
            }
          ]
        },
        {
          "id": 621493,
          "key": "625306ba-3734-47f0-aa96-6e2eb5556a7f",
          "title": "Leveraging Neural Networks",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "625306ba-3734-47f0-aa96-6e2eb5556a7f",
            "completed_at": null,
            "last_viewed_at": null,
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 626129,
              "key": "a2974f85-566e-4028-bfb4-2b16fc6ad318",
              "title": "02 Leveraging Neural Networks V3",
              "semantic_type": "VideoAtom",
              "is_public": true,
              "instructor_notes": "",
              "video": {
                "youtube_id": "thClOUTiNxY",
                "china_cdn_id": "thClOUTiNxY.mp4"
              }
            }
          ]
        },
        {
          "id": 621494,
          "key": "abe8e933-03e2-4b51-9a88-618f4e2de6f7",
          "title": "Captions and the COCO Dataset",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "abe8e933-03e2-4b51-9a88-618f4e2de6f7",
            "completed_at": null,
            "last_viewed_at": null,
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 626133,
              "key": "430ad0d1-b11e-4b7a-a7c4-9e66cdbf08dc",
              "title": "03 Captions And The COCO Dataset V3",
              "semantic_type": "VideoAtom",
              "is_public": true,
              "instructor_notes": "",
              "video": {
                "youtube_id": "DMmJs1w1n7A",
                "china_cdn_id": "DMmJs1w1n7A.mp4"
              }
            }
          ]
        },
        {
          "id": 621495,
          "key": "b551dbe7-e19f-480a-9a81-e59c9f58ff6a",
          "title": "Visualize the Dataset",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "b551dbe7-e19f-480a-9a81-e59c9f58ff6a",
            "completed_at": null,
            "last_viewed_at": null,
            "unstructured": null
          },
          "resources": {
            "files": [
              {
                "name": "Creating COCO, paper",
                "uri": "https://video.udacity-data.com/topher/2018/May/5aeb8dc7_coco-paper/coco-paper.pdf"
              }
            ],
            "google_plus_link": null,
            "career_resource_center_link": null,
            "coaching_appointments_link": null,
            "office_hours_link": null,
            "aws_provisioning_link": null
          },
          "atoms": [
            {
              "id": 621501,
              "key": "467794e4-9025-47cf-abd4-9ed38b6c4e83",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "## COCO Dataset\n\nThe COCO dataset is one of the largest, publicly available image datasets and it is meant to represent realistic scenes. What I mean by this is that COCO does not overly pre-process images, instead these images come in a variety of shapes with a variety of objects and environment/lighting conditions that closely represent what you might get if you compiled images from many different cameras around the world.\n\nTo explore the dataset, you can check out the [dataset website](http://cocodataset.org/#explore).",
              "instructor_notes": ""
            },
            {
              "id": 621503,
              "key": "e528d82d-a7e2-4670-a7d6-2069adef679d",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "### Explore\n\nClick on the explore tab and you should see a search bar that looks like the image below. Try selecting an object by it's icon and clicking search!",
              "instructor_notes": ""
            },
            {
              "id": 621504,
              "key": "f157446a-d6bd-46e5-8176-55ea45fbad41",
              "title": null,
              "semantic_type": "ImageAtom",
              "is_public": true,
              "url": "https://video.udacity-data.com/topher/2018/May/5aeb88bb_screen-shot-2018-05-03-at-3.09.44-pm/screen-shot-2018-05-03-at-3.09.44-pm.png",
              "non_google_url": "https://s3.cn-north-1.amazonaws.com.cn/u-img/f157446a-d6bd-46e5-8176-55ea45fbad41",
              "caption": "A sandwich is selected by icon.",
              "alt": "",
              "width": 600,
              "height": 914,
              "instructor_notes": null
            },
            {
              "id": 621505,
              "key": "d11a2208-d883-4beb-9978-e05293ca41c0",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "You can select or deselect multiple objects by clicking on their corresponding icon. Below are some examples for what a `sandwich` search turned up! You can see that the initial results show colored overlays over objects like sandwiches and people and the objects come in different sizes and orientations.",
              "instructor_notes": ""
            },
            {
              "id": 621506,
              "key": "c546da28-e203-4d5d-990c-f412e51eba79",
              "title": null,
              "semantic_type": "ImageAtom",
              "is_public": true,
              "url": "https://video.udacity-data.com/topher/2018/May/5aeb8986_screen-shot-2018-05-03-at-3.12.38-pm/screen-shot-2018-05-03-at-3.12.38-pm.png",
              "non_google_url": "https://s3.cn-north-1.amazonaws.com.cn/u-img/c546da28-e203-4d5d-990c-f412e51eba79",
              "caption": "COCO sandwich detections",
              "alt": "",
              "width": 600,
              "height": 570,
              "instructor_notes": null
            },
            {
              "id": 621507,
              "key": "fae07106-0163-4e76-a49f-f6e66e0befd7",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "### Captions \n\nCOCO is a richly labeled dataset; it comes with class labels, labels for segments of an image, *and* a set of captions for a given image. To see the captions for an image, select the text icon that is above the image in a toolbar. Click on the other options and see what the result is.",
              "instructor_notes": ""
            },
            {
              "id": 621508,
              "key": "ba0b12fb-5fbe-4774-8853-c9e9fb2b7cfb",
              "title": null,
              "semantic_type": "ImageAtom",
              "is_public": true,
              "url": "https://video.udacity-data.com/topher/2018/May/5aeb8a8e_screen-shot-2018-05-03-at-3.15.20-pm/screen-shot-2018-05-03-at-3.15.20-pm.png",
              "non_google_url": "https://s3.cn-north-1.amazonaws.com.cn/u-img/ba0b12fb-5fbe-4774-8853-c9e9fb2b7cfb",
              "caption": "Example captions for an image of people at a sandwich counter.",
              "alt": "",
              "width": 420,
              "height": 1036,
              "instructor_notes": null
            },
            {
              "id": 621511,
              "key": "2488047e-140e-443e-b329-08db50935718",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "When we actually train our model to generate captions, we'll be using these images as input and sampling *one* caption from a set of captions for each image to train on.",
              "instructor_notes": ""
            }
          ]
        },
        {
          "id": 621512,
          "key": "43d0cd40-10c5-4bab-bbc8-729889e219cd",
          "title": "CNN-RNN Model",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "43d0cd40-10c5-4bab-bbc8-729889e219cd",
            "completed_at": null,
            "last_viewed_at": null,
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 626135,
              "key": "a08e37e0-1ecb-4da5-b9e1-d0cb4b3e4923",
              "title": "04 CNNRNN Model V3",
              "semantic_type": "VideoAtom",
              "is_public": true,
              "instructor_notes": "",
              "video": {
                "youtube_id": "n7kdMiX1Xz8",
                "china_cdn_id": "n7kdMiX1Xz8.mp4"
              }
            }
          ]
        },
        {
          "id": 621513,
          "key": "9822e2ab-6bbc-4fcd-9a5c-0c432e93d23b",
          "title": "The Glue, Feature Vector",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "9822e2ab-6bbc-4fcd-9a5c-0c432e93d23b",
            "completed_at": null,
            "last_viewed_at": null,
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 626136,
              "key": "cce12bad-b086-4f33-bb5c-bbffb0a6de00",
              "title": "05 The Glue V5",
              "semantic_type": "VideoAtom",
              "is_public": true,
              "instructor_notes": "",
              "video": {
                "youtube_id": "u2ZdcUDnHm0",
                "china_cdn_id": "u2ZdcUDnHm0.mp4"
              }
            }
          ]
        },
        {
          "id": 621514,
          "key": "92969738-0bb4-44bb-9b40-9935234f880a",
          "title": "Tokenizing Captions",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "92969738-0bb4-44bb-9b40-9935234f880a",
            "completed_at": null,
            "last_viewed_at": null,
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 626137,
              "key": "c6639595-547d-47e2-b96a-820e0133e332",
              "title": "06 Tokenizing Captions V3",
              "semantic_type": "VideoAtom",
              "is_public": true,
              "instructor_notes": "",
              "video": {
                "youtube_id": "aeEFb0eSzJ8",
                "china_cdn_id": "aeEFb0eSzJ8.mp4"
              }
            }
          ]
        },
        {
          "id": 621524,
          "key": "055f296a-2a45-4124-8beb-b6e2b470b030",
          "title": "Tokenizing Words",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "055f296a-2a45-4124-8beb-b6e2b470b030",
            "completed_at": null,
            "last_viewed_at": null,
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 621527,
              "key": "f01c1ca2-7609-4972-b01a-02bef67534c7",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "## Words to Vectors\n\nAt this point, we know that you cannot directly feed words into an LSTM and expect it to be able to train or produce the correct output. These words first must be turned into a numerical representation so that a network can use normal loss functions and optimizers to calculate how \"close\" a predicted word and ground truth word (from a known, training caption) are. So, we typically turn a sequence of words into a sequence of numerical values; a vector of numbers where each number maps to a specific word in our vocabulary.\n\nTo process words and create a vocabulary, we'll be using the Python text processing toolkit: NLTK. in the below video, we have one of our content developers, Arpan, explain the concept of word tokenization with NLTK.",
              "instructor_notes": ""
            },
            {
              "id": 621538,
              "key": "7a5a0719-7348-41d3-b56c-b80d7224ab4c",
              "title": "Tokenization",
              "semantic_type": "VideoAtom",
              "is_public": true,
              "instructor_notes": "",
              "video": {
                "youtube_id": "4Ieotbeh4u8",
                "china_cdn_id": "4Ieotbeh4u8.mp4"
              }
            },
            {
              "id": 621536,
              "key": "7ad12979-998c-4464-a86a-5e09da6a96f2",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "Reference:\n- `nltk.tokenize` package: http://www.nltk.org/api/nltk.tokenize.html\n\nLater, you'll see how we take a tokenized representation of a caption to create a Python [dictionary](https://docs.python.org/3/tutorial/datastructures.html#dictionaries) that maps unique words in our captions dataset to unique integers.",
              "instructor_notes": ""
            }
          ]
        },
        {
          "id": 621516,
          "key": "9a3ca4b6-99d3-4fd3-bb96-770c33862ea7",
          "title": "RNN Training",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "9a3ca4b6-99d3-4fd3-bb96-770c33862ea7",
            "completed_at": null,
            "last_viewed_at": null,
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 626139,
              "key": "284effca-8818-4636-ae7c-ea7f18a6d731",
              "title": "07 RNN Training V4",
              "semantic_type": "VideoAtom",
              "is_public": true,
              "instructor_notes": "",
              "video": {
                "youtube_id": "P-tHxD7kRmA",
                "china_cdn_id": "P-tHxD7kRmA.mp4"
              }
            },
            {
              "id": 626141,
              "key": "bda0c30c-def5-4c76-9ae4-2fb8bd479418",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "## Training vs. Testing\n\nDuring training, we have a true caption which is fixed, but during testing the caption is being actively generated (starting with `<start>`), and at each step you are getting the most likely next word and using that as input to the next LSTM cell.\n\n#### Caption Generation, Test Data\n\nAfter the CNN sees a new, test image, the decoder should first produce the `<start>` token, then an output distribution at each time step that indicates the most likely next word in the sentence. We can sample the output distribution (namely, extract the one word in the distribution with the highest probability of being the next word) to get the next word in the caption and keep this process going until we get to another special token: `<end>`, which indicates that we are done generating a sentence.\n",
              "instructor_notes": ""
            }
          ]
        },
        {
          "id": 621518,
          "key": "0cd34434-f20d-4ef4-a218-d0a32efc8df1",
          "title": "Video Captioning",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "0cd34434-f20d-4ef4-a218-d0a32efc8df1",
            "completed_at": null,
            "last_viewed_at": null,
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 626321,
              "key": "e8709d9e-8af3-4fb7-a625-fe5a58980df3",
              "title": "08 Video Captioning V1",
              "semantic_type": "VideoAtom",
              "is_public": true,
              "instructor_notes": "",
              "video": {
                "youtube_id": "I_m9JyKTfbQ",
                "china_cdn_id": "I_m9JyKTfbQ.mp4"
              }
            }
          ]
        },
        {
          "id": 621519,
          "key": "0d249393-d316-4e5b-bd6b-c16f439909d0",
          "title": "On to the Project!",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "0d249393-d316-4e5b-bd6b-c16f439909d0",
            "completed_at": null,
            "last_viewed_at": null,
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 626149,
              "key": "8bd15173-3ae2-4e53-9aa5-d554ba8f8026",
              "title": "09 On To The Project V2",
              "semantic_type": "VideoAtom",
              "is_public": true,
              "instructor_notes": "",
              "video": {
                "youtube_id": "MsxNRaYTNSk",
                "china_cdn_id": "MsxNRaYTNSk.mp4"
              }
            },
            {
              "id": 633913,
              "key": "d3763d69-4bec-4ce0-ad12-ead78c0fcd7b",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "## Want to Learn more from Kelvin?\n\nKelvin has worked with us on one more high-level lesson about fully-convolutional networks (FCN's). To learn more from him and about a complex deep learning model, I suggest you check out the elective section: **Elective: More Deep Learning Models** and go to Fully-Convolutional Networks!",
              "instructor_notes": ""
            }
          ]
        }
      ]
    }
  },
  "_deprecated": [
    {
      "name": "non_google_url",
      "reason": "(2016/8/18) Not sure, ask i18n team for reason"
    },
    {
      "name": "non_google_url",
      "reason": "(2016/8/18) Not sure, ask i18n team for reason"
    },
    {
      "name": "non_google_url",
      "reason": "(2016/8/18) Not sure, ask i18n team for reason"
    }
  ]
}